<!DOCTYPE html>
<html lang="en" xmlns="">

<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <script type="text/javascript"
          src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta charset="utf-8">
  <title>Dexterity with Multifingered Hands: Hardware, Sensing, and Skills</title>
  <link rel="stylesheet" href="css/style.css">
</head>

<body>
<div class="nav">
  <div class="nav-container">
    <a href="https://dex-manipulation.github.io/rss2026/index.html#intro">Introduction</a>
    <a href="https://dex-manipulation.github.io/rss2026/index.html#speaker">Speakers</a>
    <a href="https://dex-manipulation.github.io/rss2026/index.html#call">Call for Papers</a>
    <a href="https://dex-manipulation.github.io/rss2026/index.html#schedule">Schedule</a>
    <a href="https://dex-manipulation.github.io/rss2026/index.html#organizers">Organizers</a>
    <a href="https://dex-manipulation.github.io/rss2026/index.html#contact">Contact</a>
  </div>
</div>

<div class="title-container">
  <div style="text-align: center;">
    <h1>4th Workshop on Dexterous Manipulation: <br> Scalable Learning for Human-Level Skills</h1>
    <div class="subtitle" style="color: #ccc; margin: 20px">
      RSS 2026 Workshop Proposal
    </div>
<!--    <div class="subtitle" style="color: #ccc; margin: 20px">-->
<!--      <a href="https://www.youtube.com/watch?v=7a5HYjQ4wJo">[Recording]</a>-->
<!--    </div>-->
<!--    <div class="subtitle" style="color: #ccc; margin: 20px">-->
<!--      Location: OHE 122-->
<!--    </div>-->
<!--    <div class="subtitle" style="color: #ccc; margin: 20px">-->
<!--      Poster Stand Number: 35 - 60 (Epstein Plaza)-->
<!--    </div>-->
  </div>
</div>

<div class="container">
  <div class="section" id="intro">
    <h2>Introduction</h2>
    <p>
      Dexterous manipulation is entering a pivotal transformation in 2026. While it
      remains a grand challenge, the bottleneck is shifting. We are moving from a scarcity of capable
      hardware to an era of accessible, robust hands, and from small-scale teleoperation data to
      internet-scale human video learning. The core question for this year is no longer just "how do
      we control these hands?" but "how do we scale dexterity by leveraging massive video datasets,
      reliable hardware, and sim-to-real pipelines?
    </p>
    <p>
      This workshop will bring together researchers from academia and industry to explore answers,
      with themes spanning manipulation bottlenecks, algorithmic advances, improved adaptability,
      and future directions. Through invited talks, spotlight presentations, posters, and a panel
      discussion, participants will exchange perspectives and build collaborations that drive progress
      toward practical dexterous manipulation.
    </p>
  </div>


  <div class="section" id="speakers">
    <h2>Invited Speakers</h2>

    <div class="people">
      <a href="https://web.stanford.edu/~bohg/">
        <img src="../profiles/jb.png">
        <div>Jeannette Bohg</div>
        <div class="aff">Stanford</div>
      </a>

      <a href="https://www.tu.berlin/en/robotics/about-rbo/prof-dr-oliver-brock">
        <img src="../profiles/oliver_brock.jpg">
        <div>Oliver Brock</div>
        <div class="aff">TU Berlin</div>
      </a>

      <a href="https://www.mccormick.northwestern.edu/research-faculty/directory/profiles/colgate-edward.html">
        <img src="../profiles/edward_colgate.jpg">
        <div>J. Ed Colgate</div>
        <div class="aff">Northwestern University</div>
      </a>

      <a href="https://fang-haoshu.github.io/">
        <img src="../profiles/haoshu_fang.png">
        <div>Hao-Shu Fang</div>
        <div class="aff">University of Maryland</div>
      </a>

      <a href="https://irmakguzey.github.io/">
        <img src="../profiles/irmak_guzey.jpeg">
        <div>Irmak Guzey</div>
        <div class="aff">New York University</div>
      </a>

      <a href="https://www.weimingzhi.com/">
        <img src="../profiles/weiming_zhi.jpg">
        <div>Weiming Zhi</div>
        <div class="aff">University of Sydney</div>
      </a>

    </div>
    <p> (<small><i>listed alphabetically</i></small>) </p>
  </div>
  <br>

  <div class="section" id="schedule">
    <h2>Workshop Schedule (TBD)</h2>

<!--    <style type="text/css">-->
<!--        .tg .tg-u4qn {-->
<!--            background-color: #D9D9D9;-->
<!--            text-align: left;-->
<!--            vertical-align: bottom-->
<!--        }-->
<!--    </style>-->
<!--    <table>-->
<!--      <tr>-->
<!--        <th>Time (UTC -8)</th>-->
<!--        <th>Event</th>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>08:55 - 09:00</td>-->
<!--        <td>Introduction and Opening Remark</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>09:00 - 09:30</td>-->
<!--        <td>Invited Talk (Karen Liu)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>09:30 - 10:00</td>-->
<!--        <td>Invited Talk (Sudharshan Suresh)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>10:00 - 10:30</td>-->
<!--        <td>Invited Talk (Jessica Yin)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>10:30 - 11:00</td>-->
<!--        <td>Spotlight Session 1:-->
<!--          <ul>-->
<!--            <li> ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation </li>-->
<!--            <li> Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy </li>-->
<!--            <li> HuDOR: Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards </li>-->
<!--            <li> RUKA: Rethinking the Design of Humanoid Hands with Learning </li>-->
<!--            <li> DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation </li>-->
<!--            <li> Scaffolding Dexterous Manipulation with Vision-Language Models </li>-->
<!--          </ul>-->
<!--        </td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>11:00 - 11:30</td>-->
<!--        <td>Poster / Demo Session</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>11:30 - 12:00</td>-->
<!--        <td>Invited Talk (Ankur Handa)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>14:00 - 14:30</td>-->
<!--        <td>Invited Talk (Russ Tedrake)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>14:30 - 15:00</td>-->
<!--        <td>Invited Talk (Wanxin Jin)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>15:00 - 15:30</td>-->
<!--        <td>Invited Talk (Huazhe Xu)</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>15:30 - 16:00</td>-->
<!--        <td>Spotlight Session 2-->
<!--          <ul>-->
<!--            <li> DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies </li>-->
<!--            <li> Reinforcement Learning for Ambidextrous Bimanual Manipulation via Morphological Symmetry </li>-->
<!--            <li> Learning Particle-Based World Model from Human for Robot Dexterous Manipulation </li>-->
<!--            <li> DEXOS: Hand Exoskeleton System for Teaching Robot Dexterous Manipulation In-The-Wild </li>-->
<!--            <li> Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation </li>-->
<!--            <li> ImVR: Immersive VR Teleoperation System for General Purpose </li>-->
<!--            <li> Dexterous Contact-Rich Manipulation via the Contact Trust Region </li>-->
<!--          </ul>-->
<!--        </td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>16:00 - 16:30</td>-->
<!--        <td>Poster / Demo Session</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>16:30 - 17:25</td>-->
<!--        <td>Panel Discussion</td>-->
<!--      </tr>-->
<!--      <tr>-->
<!--        <td>17:25 - 17:30</td>-->
<!--        <td>Closing Remark & Award Ceremony</td>-->
<!--      </tr>-->
<!--    </table>-->
  </div>
  <br>

<!--  <div class="section" id="papers">-->
<!--    <h2>Accepted Papers</h2>-->
<!--    <ul>-->
<!--      <li><a href='https://openreview.net/forum?id=5udqMOeai1'>Tool-as-Interface: Learning Robot Policies from Observing Human Tool Use</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=beQYTjx17x'>DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=c8wl1O12GH'>FLARE: Robot Learning with Implicit World Modeling</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=u3rYstjrpk'>Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=Lsej3WBwQj'>DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=ScRpDkgNJL'>DexNoMa: Learning Geometry-Aware Nonprehensile Dexterous Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=wmxeNgRUTh'>X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=lujxPiu99k'>ImMimic: Cross-Domain Imitation from Human Videos via Mapping and Interpolation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=3zuBUoic2n'>Learning Particle-Based World Model from Human for Robot Dexterous Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=Sxwc7oo9tg'>Reinforcement Learning for Ambidextrous Bimanual Manipulation via Morphological Symmetry</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=S0FmCZ6by5'>DREAM: Differentiable Real-to-Sim-to-Real Engine for Learning Robotic Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=no55YX03LT'>Dexonomy: Synthesizing All Dexterous Grasp Types in a Grasp Taxonomy</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=M2uezh5gZ2'>HuDOR: Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=Uf6SfYxjld'>RUKA: Rethinking the Design of Humanoid Hands with Learning</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=chOIumE4X5'>ZeroMimic: Distilling Robotic Manipulation Skills from Web Videos</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=XSdKoJKyH2'>Scaffolding Dexterous Manipulation with Vision Language Models</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=FVNOREWicy'>ViTaSCOPE: Visuo-tactile Implicit Representation for In-hand Pose and Extrinsic Contact Estimation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=97wHM52YU3'>DEXOP: Hand Exoskeleton System for Teaching Robot Dexterous Manipulation In-The-Wild</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=Y6ktqKRDeZ'>Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=7xCorSm0p7'>eFlesh: Highly customizable Magnetic Touch Sensing using Cut-Cell Microstructures</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=C5GMHp14ib'>Touch begins where vision ends: Generalizable policies for contact-rich manipulation</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=JWF70OQxTS'>Learning Dexterous Deformable Object Manipulation Through Cross-Embodiment Dynamics Learning</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=26wkb05i8h'>ImVR: Immersive VR Teleoperation System for General Purpose</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=1FkgX44cJW'>Dexterous Contact-Rich Manipulation via the Contact Trust Region</a></li>-->
<!--      <li><a href='https://openreview.net/forum?id=QM6nVfejPd'>DexWrist: A Robotic Wrist for Constrained and Dynamic Manipulation</a></li>-->
<!--    </ul>-->
<!--  </div>-->

  <div class="section" id="call">
    <h2>Call for Papers/Demos (TBD)</h2>
<!--    <p>-->
<!--      In this workshop, our goal is to bring together researchers from various fields of robotics, such as control,-->
<!--      optimization, learning, planning, sensing, hardware, etc., who work on dexterous manipulation.-->
<!--    </p>-->

<!--    <p>-->
<!--  Each accepted short paper will be eligible for a poster presentation. Selected papers will also have the opportunity to give a short spotlight talk.-->
<!--  <b>Note: Both poster and spotlight presentations must be given in person.</b>-->
<!--    </p>-->

<!--    <p>-->
<!--      We are particularly excited to offer a platform for showcasing real-world robotic systems.-->
<!--      <b style="color: darkblue">Even without a formal paper, we encourage submissions of videos demonstrating your-->
<!--        robots in action. For those-->
<!--        able to attend in person, there will be opportunities to showcase your robots live at the workshop!</b>-->
<!--      We encourage-->
<!--      researchers to submit work in the following areas (the list is not exhaustive):-->
<!--    </p>-->

<!--    <ul>-->
<!--      <li><strong>Learning for Dexterous Manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>Can we expect a foundation policy for most daily dexterous manipulation tasks, or will-->
<!--                each task require its own policy?-->
<!--              </li>-->
<!--              <li>How can learning-based policies handle dynamic tasks that require high-frequency control?-->
<!--              </li>-->
<!--              <li>-->
<!--                How can we improve the generalization capability or the sample efficiency of policy learning in dexterous-->
<!--                manipulation?-->
<!--              </li>-->
<!--            </ul>-->
<!--      <li><strong>Planning and Optimization in Dexterous Manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>How to scale up planning/optimization methods to high DoF systems?-->
<!--              </li>-->
<!--              <li>-->
<!--                How to leverage both planning/optimization methods and learning methods to get the best of both worlds?-->
<!--              </li>-->
<!--              <li>How can we make dexterous hands compliant?</li>-->
<!--            </ul>-->
<!--      <li><strong>Simulation for contact-rich manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>How to better model the contacts between the hand and object?-->
<!--              </li>-->
<!--              <li>How can we speed up simulation in the presence of frequent contacts?-->
<!--              </li>-->
<!--            </ul>-->
<!--      <li><strong>Hardware design for Dexterous Manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>Is it possible to build a low-cost dexterous hand?-->
<!--              </li>-->
<!--              <li>What kind of hand design can make manipulation easier?-->
<!--              </li>-->
<!--              <li>-->
<!--                What benefits do soft hands bring?-->
<!--              </li>-->
<!--              <li>-->
<!--                Novel mechanisms that improve robotic hand performance.-->
<!--              </li>-->
<!--            </ul>-->
<!--      <li><strong>Data collection in Dexterous Manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>How do we leverage human hand data in the wild to improve policy learning in dexterous manipulation?-->
<!--              </li>-->
<!--              <li>How to develop low-cost, easy-to-use teleoperation systems for large-scale demonstration data?-->
<!--              </li>-->
<!--              <li>How do we leverage planning methods to generate large-scale demonstration data in simulation?</li>-->
<!--            </ul>-->
<!--      <li><strong>Tactile Sensing for Manipulation</strong></li>-->
<!--            <ul>-->
<!--              <li>What's the role of tactile sensing for dexterous manipulation?-->
<!--              </li>-->
<!--              <li>-->
<!--                How to use tactile data efficiently for control or policy learning?-->
<!--              </li>-->
<!--            </ul>-->

<!--      <li>Any additional related topics not already covered in the above list ðŸ˜„</li>-->
<!--    </ul>-->
<!--    <h3>Submission Guidelines</h3>-->
<!--    <p>-->
<!--    <ul>-->
<!--      <li><b style="color: darkblue">Submission Portal for Paper and Demo:</b> <a-->
<!--          href="https://openreview.net/group?id=roboticsfoundation.org/RSS/2025/Workshop/Dex"-->
<!--          target="_blank">OpenReview</a>-->
<!--      </li>-->
<!--      <li><b style="color: darkblue">Paper Submission Guideline:</b></li>-->
<!--      <ul>-->
<!--        <li><b>Paper Length:</b>-->
<!--          Submissions could be <b>4-page</b> short papers, excluding references, acknowledgements, and appendices.-->
<!--        </li>-->
<!--        <li><b>Format:</b>-->
<!--          <ul>-->
<!--            <li>The format requirement follows the RSS 2025 main conference. Paper template: <a-->
<!--                href="https://roboticsconference.org/docs/paper-template-latex.tar.gz" target="_blank">LaTeX</a> and <a-->
<!--                href="https://roboticsconference.org/docs/paper-template-word.zip" target="_blank">Word</a></li>-->
<!--            <li>Please include the references and appendix in the same PDF as the main paper and submit optional videos-->
<!--              as zip file in supplementary.-->
<!--            </li>-->
<!--            <li>The maximum file size is 100MB. More information on-->
<!--              format can be found <a-->
<!--                  href="https://roboticsconference.org/information/authorinfo/#paper-and-demo-format"-->
<!--                  target="_blank">here</a>.-->
<!--            </li>-->
<!--          </ul>-->
<!--        </li>-->
<!--        <li><b>Dual Submission for Other Conference:</b>-->
<!--          <ul>-->
<!--            <li>Papers to be submitted or in preparation for submission to other major venues (including CoRL 2024) in-->
<!--              the-->
<!--              field are allowed.-->
<!--            </li>-->
<!--            <li>We also welcome published works as long as explicitly stated at the time of submission.</li>-->
<!--          </ul>-->
<!--        </li>-->
<!--      </ul>-->

<!--      <li><b style="color: darkblue">Demo Submission Guideline:</b></li>-->
<!--      <ul>-->
<!--        <li><b>Summary Document:</b>-->
<!--          Please upload a summary document as a pdf. There is no page and format requirement for this pdf.-->
<!--        </li>-->
<!--        <li><b>Demo Video:</b>-->
<!--          Please upload video demos as a single zip under the supplementary material field in OpenReview.-->
<!--        </li>-->
<!--      </ul>-->
<!--      <li><b style="color: darkblue">Visibility:</b> Submissions and reviews will not be public. Only accepted papers-->
<!--        will be made public.-->
<!--      </li>-->
<!--    </ul>-->

<!--    <h3>Timeline</h3>-->
<!--    <ul>-->
<!--      <li>Submission Port Open: <b>May 7, 2025</b></li>-->
<!--      <li>Submission Deadline: <b style="color: red;"><del>May 29, 2025</del> June 1, 2025 (PT)</b></li>-->
<!--      <li>Notification: <b style="color: red;"><del>Jun 10, 2025</del> June 14, 2025 (PT)</b></li>-->
<!--      <li>Workshop Date: <b>June 25, 2025</b></li>-->
<!--    </ul>-->

  </div>

  <div class="section" id="organizers">
    <h2>Organizers</h2>
    <div class="people">
      <a href="https://haozhi.io/">
        <img src="../profiles/haozhi_qi.jpg">
        <div>Haozhi Qi</div>
        <div class="aff">Amazon FAR & University of Chicago</div>
      </a>
      <a href="https://kennyshaw.net/">
        <img src="../profiles/kenny_shaw.jfif">
        <div>Kenneth Shaw</div>
        <div class="aff">Carnegie Mellon University</div>
      </a>
      <a href="https://amberxie88.github.io/">
        <img src="../profiles/amber_xie.png">
        <div>Amber Xie</div>
        <div class="aff">Stanford University</div>
      </a>
      <a href="https://changhaowang.github.io/">
        <img src="../profiles/changhao_wang.jpg">
        <div>Changhao Wang</div>
        <div class="aff">Stanford University</div>
      </a>
      <a href="https://harishravichandar.com/">
        <img src="../profiles/harish_ravichandar.jpg">
        <div>Harish Ravichandar</div>
        <div class="aff">Georgia Tech</div>
      </a>
      <a href="https://pathak22.github.io/">
        <img src="../profiles/deepak_pathak.jpeg">
        <div>Deepak Pathak</div>
        <div class="aff">Carnegie Mellon University</div>
      </a>
    </div>
  </div>

<!--  <div class="section" id="sponsor">-->
<!--    <h2>Sponsor</h2>-->
<!--    <div>-->
<!--      <img src="images/dexmate.jpg" style="display: block; height: 120px " alt="DEXMATE">-->
<!--    </div>-->
<!--  </div>-->

  <div class="section" id="contact">
    <h2>Contact</h2>
    <div>For questions and comments, please <a href="mailto:haozhi@uchicago.edu">contact us.</a>
    </div>
  </div>

  <div class="foot">
    Â© ICRA 2026 Dexterous Manipulation Workshop
  </div>
</div>


</body>

</html>